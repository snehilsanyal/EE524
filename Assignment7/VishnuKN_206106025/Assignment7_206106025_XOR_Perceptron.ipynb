{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 7 :  XOR gate boolean perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sigmoid Activation function\n",
    "def node(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def derivative_node(sx):\n",
    "    return sx * (1 - sx)\n",
    "\n",
    "def cost(predicted, truth):\n",
    "    return truth - predicted\n",
    "\n",
    "def predict_perceptron(inputs,w1,w2):\n",
    "    \n",
    "    inputlayer=np.dot(inputs,w1)\n",
    "    hiddenoutput=node(inputlayer)\n",
    "    outputlayer=np.dot(hiddenoutput,w2)\n",
    "    output=node(outputlayer)\n",
    "           \n",
    "    return output\n",
    "\n",
    "def train_perceptron(traindata,w1,w2,itermax = 10000,ratelearn = 1.0):\n",
    "\n",
    "    for epoch_n in range(itermax):\n",
    "\n",
    "## Forward Propagation  \n",
    "        layer0 = traindata # Input layer\n",
    "        layer1 = node(np.dot(layer0, w1)) # Hidden layer\n",
    "        layer2 = node(np.dot(layer1, w2)) # Output layer\n",
    "    \n",
    "## BackPropagation\n",
    "    ## Output Layer ---> Hidden Layer\n",
    "        layer2Error = cost(layer2, trainlabels) # errors\n",
    "        layer2Step = layer2Error*derivative_node(layer2) # gradient descend\n",
    "\n",
    "    ## Hidden Layer ---> Input Layer   \n",
    "        layer1Error = np.dot(layer2Step, np.transpose(w2)) #Error\n",
    "        layer1Step = layer1Error*derivative_node(layer1) # Gradient descend\n",
    "    \n",
    "    # update weights\n",
    "        w2 +=  ratelearn*np.dot(np.transpose(layer1), layer2Step)\n",
    "        w1 +=  ratelearn*np.dot(np.transpose(layer0), layer1Step)\n",
    "        \n",
    "    return w1,w2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "XORinput = np.array([[0,0], [0,1], [1,0], [1,1]])\n",
    "XORoutput = np.transpose(np.array([[0,1,1,0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Droping the labels/output for testing\n",
    "traindata = XORinput\n",
    "trainlabels = XORoutput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No of nodes in the hidden layer\n",
    "nHiddenNodes = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## initializing weight vector input node ---> hidden node\n",
    "## Input Nodes ---> 2\n",
    "## Hidden Nodes ---> 2\n",
    "w1initial = np.random.random((2, nHiddenNodes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## initializing weight vector hidden node ---> output node\n",
    "## Hidden Nodes ---> 2\n",
    "## Output Nodes ---> 1\n",
    "w2initial = np.random.random((nHiddenNodes, 1))\n",
    "#wlayer2 = np.zeros((nHiddenNodes,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "wlayer1,wlayer2=train_perceptron(traindata,w1initial,w2initial)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing the learned weights for an input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The XOR gate with learned weights\n",
      "\n",
      "Input ---> ([0 0]) --->|XOR|---> [0.]\n",
      "Input ---> ([0 1]) --->|XOR|---> [1.]\n",
      "Input ---> ([1 0]) --->|XOR|---> [1.]\n",
      "Input ---> ([1 1]) --->|XOR|---> [0.]\n",
      "\n",
      "The learned weights are\n",
      "\n",
      "Layer 1 Weights\n",
      "\n",
      "[[0.92618764 7.7167131 ]\n",
      " [0.92618844 7.71715679]]\n",
      "\n",
      "\n",
      "Layer 2 Weights\n",
      "\n",
      "[[-33.0486919 ]\n",
      " [ 26.28244689]]\n"
     ]
    }
   ],
   "source": [
    "testdata=np.array([[0,0],[0,1],[1,0],[1,1]])\n",
    "outprediction=[]\n",
    "print('The XOR gate with learned weights\\n')\n",
    "for i in range(len(testdata)):\n",
    "    outprediction.append(predict_perceptron([testdata[i]],wlayer1,wlayer2))\n",
    "    print('Input ---> ('+str(testdata[i])+') --->|XOR|---> ['+str(np.round(outprediction[i]))[2:-2]+']')\n",
    "\n",
    " \n",
    "print('\\nThe learned weights are')\n",
    "print('\\nLayer 1 Weights\\n')\n",
    "print(wlayer1)\n",
    "print('\\n\\nLayer 2 Weights\\n')\n",
    "print(wlayer2)\n",
    "## printing the parameters as a line and the decision boundary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
